{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FU-HwvIdH0M-"
   },
   "source": [
    "# Sentiment analysis \n",
    "\n",
    "The objective of the second problem is to perform Sentiment analysis from the tweets collected from the users targeted at various mobile devices.\n",
    "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aIWWfNks5sYa"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAQDiZHRH0M_"
   },
   "source": [
    "### Read the data\n",
    "- read tweets.csv\n",
    "- use latin encoding if it gives encoding error while loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eXGIe-SH0NA"
   },
   "outputs": [],
   "source": [
    "tweets_df=pd.read_csv('tweets.csv',encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39pqw0aE5sYe"
   },
   "source": [
    "### Drop null values\n",
    "- drop all the rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8219</th>\n",
       "      <td>Apple just brought is water in the iPad line #...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>Looking for an iPhone app that manages multipl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>Just because google patented something i.e. (A...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>RT @mention VERY IMPORTANT: Make sure you are ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>In iPad Design Headaches: Take Two Tablets, Ca...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "8219  Apple just brought is water in the iPad line #...   \n",
       "7126  Looking for an iPhone app that manages multipl...   \n",
       "8712  Just because google patented something i.e. (A...   \n",
       "6839  RT @mention VERY IMPORTANT: Make sure you are ...   \n",
       "3056  In iPad Design Headaches: Take Two Tablets, Ca...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "8219                             NaN   \n",
       "7126                             NaN   \n",
       "8712                             NaN   \n",
       "6839                             NaN   \n",
       "3056                            iPad   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "8219                 No emotion toward brand or product  \n",
       "7126                 No emotion toward brand or product  \n",
       "8712                                   Negative emotion  \n",
       "6839                 No emotion toward brand or product  \n",
       "3056                                   Negative emotion  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_new=tweets_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3291, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0bm4bDiy5sYg"
   },
   "source": [
    "### Print the dataframe\n",
    "- print initial 5 rows of the data\n",
    "- use df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ceSlvAVa5sYh",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcWfPVqG5sYi"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JBbAeip_5sYj"
   },
   "source": [
    "### Preprocess data\n",
    "- convert all text to lowercase - use .lower()\n",
    "- select only numbers, alphabets, and #+_ from text - use re.sub()\n",
    "- strip all the text - use .strip()\n",
    "    - this is for removing extra spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QlMvbtrK5sYl"
   },
   "source": [
    "print dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_new=tweets_new.applymap(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_new=tweets_new.applymap(lambda x:re.sub('[^0-9a-zA-Z\\#\\+\\_\\s]','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_new=tweets_new.applymap(lambda x:x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>swonderlin can not wait for #ipad 2 also they ...</td>\n",
       "      <td>ipad</td>\n",
       "      <td>positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxtxstate great stuff on fri #sxsw marissa may...</td>\n",
       "      <td>google</td>\n",
       "      <td>positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  wesley83 i have a 3g iphone after 3 hrs tweeti...   \n",
       "1  jessedee know about fludapp  awesome ipadiphon...   \n",
       "2  swonderlin can not wait for #ipad 2 also they ...   \n",
       "3  sxsw i hope this years festival isnt as crashy...   \n",
       "4  sxtxstate great stuff on fri #sxsw marissa may...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iphone   \n",
       "1              ipad or iphone app   \n",
       "2                            ipad   \n",
       "3              ipad or iphone app   \n",
       "4                          google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   negative emotion  \n",
       "1                                   positive emotion  \n",
       "2                                   positive emotion  \n",
       "3                                   negative emotion  \n",
       "4                                   positive emotion  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new.head()\n",
    "\n",
    "## printing the dataframe after applying all the prepocessing data techniques as per the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bcTUnvtg5sYn"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4gnaeSXZ5sYo"
   },
   "source": [
    "### Preprocess data\n",
    "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
    "    - select only those rows where value equal to \"positive emotion\" or \"negative emotion\"\n",
    "- find the value counts of \"positive emotion\" and \"negative emotion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_new = tweets_new[(tweets_new[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"positive emotion\") | (tweets_new[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"negative emotion\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive emotion    2672\n",
       "negative emotion     519\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new[\"is_there_an_emotion_directed_at_a_brand_or_product\"].value_counts()\n",
    "\n",
    "## selected and showing the count of rows that have value equal to positive or negative emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6icGcVTE5sYz"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rg0rSepj5sYz"
   },
   "source": [
    "### Encode labels\n",
    "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
    "    - change \"positive emotion\" to 1\n",
    "    - change \"negative emotion\" to 0\n",
    "- use map function to replace values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sms['label_num'] = sms.label.map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YftKwFv7H0N9"
   },
   "outputs": [],
   "source": [
    "tweets_new['Label'] = tweets_new[\"is_there_an_emotion_directed_at_a_brand_or_product\"].map({'positive emotion': '1', 'negative emotion': '0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
       "      <td>iphone</td>\n",
       "      <td>negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>swonderlin can not wait for #ipad 2 also they ...</td>\n",
       "      <td>ipad</td>\n",
       "      <td>positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
       "      <td>ipad or iphone app</td>\n",
       "      <td>negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxtxstate great stuff on fri #sxsw marissa may...</td>\n",
       "      <td>google</td>\n",
       "      <td>positive emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  wesley83 i have a 3g iphone after 3 hrs tweeti...   \n",
       "1  jessedee know about fludapp  awesome ipadiphon...   \n",
       "2  swonderlin can not wait for #ipad 2 also they ...   \n",
       "3  sxsw i hope this years festival isnt as crashy...   \n",
       "4  sxtxstate great stuff on fri #sxsw marissa may...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iphone   \n",
       "1              ipad or iphone app   \n",
       "2                            ipad   \n",
       "3              ipad or iphone app   \n",
       "4                          google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product Label  \n",
       "0                                   negative emotion     0  \n",
       "1                                   positive emotion     1  \n",
       "2                                   positive emotion     1  \n",
       "3                                   negative emotion     0  \n",
       "4                                   positive emotion     1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_new.head()\n",
    "\n",
    "## assigned a label of 0 to negative emotion and 1 to positive emotion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sC1qSe3h5sY2"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWlAN_Ts5sY2"
   },
   "source": [
    "### Get feature and label\n",
    "- get column \"tweet_text\" as feature\n",
    "- get column \"is_there_an_emotion_directed_at_a_brand_or_product\" as label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9A3sOZzR5sY4"
   },
   "outputs": [],
   "source": [
    "X=tweets_new.tweet_text\n",
    "y=tweets_new.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3191,)\n",
      "(3191,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YErwYLCH0N_"
   },
   "source": [
    "### Create train and test data\n",
    "- use train_test_split to get train and test set\n",
    "- set a random_state\n",
    "- test_size: 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNkwrGgEH0OA"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=7)\n",
    "\n",
    "## splitting the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2393,)\n",
      "(798,)\n",
      "(2393,)\n",
      "(798,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMok2IX35sY8"
   },
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSqYjPuT5sY8"
   },
   "source": [
    "### Vectorize data\n",
    "- create document-term matrix\n",
    "- use CountVectorizer()\n",
    "    - ngram_range: (1, 2)\n",
    "    - stop_words: 'english'\n",
    "    - min_df: 2   \n",
    "- do fit_transform on X_train\n",
    "- do transform on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bb9PnnqT5sY8"
   },
   "outputs": [],
   "source": [
    "vect=CountVectorizer(ngram_range=(1, 2),stop_words='english',min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2393x5383 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 37278 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm=vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<798x5383 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 10661 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qanDXve15sY_"
   },
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMaRNFkV5sY_"
   },
   "source": [
    "### Select classifier logistic regression\n",
    "- use logistic regression for predicting sentiment of the given tweet\n",
    "- initialize classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GT3dNgB55sZA"
   },
   "outputs": [],
   "source": [
    "logreg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqQ6_HX35sZD"
   },
   "source": [
    "### Fit the classifer\n",
    "- fit logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EIzvnNkq5sZD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZpMsYQF5sZF"
   },
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGnQnUww5sZF"
   },
   "source": [
    "### Select classifier naive bayes\n",
    "- use naive bayes for predicting sentiment of the given tweet\n",
    "- initialize classifier\n",
    "- use MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AbVYssaH0OE"
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QEaG942m5sZI"
   },
   "source": [
    "### Fit the classifer\n",
    "- fit naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLwRBj1R5sZI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7mgwYDJ5sZM"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZkA3tce5sZN"
   },
   "source": [
    "### Make predictions on logistic regression\n",
    "- use your trained logistic regression model to make predictions on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l3f0M1ch5sZO"
   },
   "outputs": [],
   "source": [
    "y_predict_test=logreg.predict(X_test_dtm)\n",
    "\n",
    "## making predictions on X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1',\n",
       "       '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '0', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '0', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1',\n",
       "       '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrIxjMUB5sZQ"
   },
   "source": [
    "### Make predictions on naive bayes\n",
    "- use your trained naive bayes model to make predictions on X_test\n",
    "- use a different variable name to store predictions so that they are kept separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSQnwyLU5sZQ"
   },
   "outputs": [],
   "source": [
    "y_predict_testnb=nb.predict(X_test_dtm)\n",
    "\n",
    "## using NB model to make predictions on X_test. Storing the results in a separate variable as per requirement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '0', '1',\n",
       "       '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '0',\n",
       "       '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '0', '1', '1'], dtype='<U1')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_testnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rwXQUE7b5sZS"
   },
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E6SITIE75sZT"
   },
   "source": [
    "### Calculate accuracy of logistic regression\n",
    "- check accuracy of logistic regression classifer\n",
    "- use sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clv2X0kKH0Ok"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87468671679198"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_predict_test)\n",
    "\n",
    "## checking accuracy on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train=logreg.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9715837860426243"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train, y_predict_train)\n",
    "\n",
    "## checking accuracy on train data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Fd_Gnd05sZV"
   },
   "source": [
    "### Calculate accuracy of naive bayes\n",
    "- check accuracy of naive bayes classifer\n",
    "- use sklearn.metrics.accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d32uBpHi5sZW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_predict_testnb)\n",
    "\n",
    "## checking accuracy on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_trainnb=nb.predict(X_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9348098620977852"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_train, y_predict_trainnb)\n",
    "\n",
    "## checking accuracy on train data "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R8_Lab_Questions_GurgoanAug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
